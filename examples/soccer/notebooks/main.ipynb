{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soccer AI Video Analysis\n",
    "\n",
    "This notebook provides computer vision tools for analyzing soccer videos including:\n",
    "- Pitch detection\n",
    "- Player detection and tracking\n",
    "- Ball detection\n",
    "- Team classification\n",
    "- Radar view generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting supervision\n",
      "  Downloading supervision-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (1.16.3)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (3.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (6.0.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision) (11.3.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.67.2)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.13.0.90)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (26.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2026.1.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
      "Downloading supervision-0.27.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: supervision\n",
      "Successfully installed supervision-0.27.0\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.4.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.13.0.90)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Downloading ultralytics-8.4.12-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.4.12 ultralytics-thop-2.0.18\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
      "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install supervision --break-system-packages\n",
    "!pip install ultralytics --break-system-packages\n",
    "!pip install tqdm --break-system-packages\n",
    "!pip install opencv-python --break-system-packages\n",
    "!pip install numpy --break-system-packages\n",
    "\n",
    "# Install sports package (assuming it's available)\n",
    "# If sports is a custom package, you may need to install it differently\n",
    "# !pip install sports --break-system-packages\n",
    "# Or if it's a local package:\n",
    "# !pip install -e /path/to/sports --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/roboflow/sports.git\n",
      "  Cloning https://github.com/roboflow/sports.git to /tmp/pip-req-build-mk5t3pyy\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/roboflow/sports.git /tmp/pip-req-build-mk5t3pyy\n",
      "  Resolved https://github.com/roboflow/sports.git to commit 42c80c06b6b65a7f89455b89fe31cdf4c38ba227\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: supervision in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (0.27.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (2.0.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (4.13.0.90)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (5.0.0)\n",
      "Requirement already satisfied: umap-learn in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (0.5.11)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (1.6.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (4.67.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (0.2.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from sports==0.1.0) (5.29.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sports==0.1.0) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sports==0.1.0) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sports==0.1.0) (3.6.0)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision->sports==0.1.0) (3.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision->sports==0.1.0) (6.0.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->sports==0.1.0) (0.7.1)\n",
      "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision->sports==0.1.0) (11.3.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision->sports==0.1.0) (2.32.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->sports==0.1.0) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers->sports==0.1.0) (1.3.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->sports==0.1.0) (26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->sports==0.1.0) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->sports==0.1.0) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers->sports==0.1.0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->sports==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn->sports==0.1.0) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn->sports==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (4.15.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->sports==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->sports==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->sports==0.1.0) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->sports==0.1.0) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->sports==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->sports==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.2->umap-learn->sports==0.1.0) (0.43.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->sports==0.1.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->sports==0.1.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->sports==0.1.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->sports==0.1.0) (2026.1.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers->sports==0.1.0) (8.3.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->sports==0.1.0) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision->sports==0.1.0) (1.17.0)\n",
      "Building wheels for collected packages: sports\n",
      "  Building wheel for sports (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sports: filename=sports-0.1.0-py3-none-any.whl size=10881 sha256=6e9e1eeadd6bd4dd3e4c2593886152a411d1ca4c023c86bba266cf2028665e2a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t7abpded/wheels/6f/53/b4/9ae665e952091404183bcf40f7662061b8d46a5eb80ae595da\n",
      "Successfully built sports\n",
      "Installing collected packages: sports\n",
      "Successfully installed sports-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/roboflow/sports.git --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from enum import Enum\n",
    "from typing import Iterator, List\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from sports.annotators.soccer import draw_pitch, draw_points_on_pitch\n",
    "from sports.common.ball import BallTracker, BallAnnotator\n",
    "from sports.common.team import TeamClassifier\n",
    "from sports.common.view import ViewTransformer\n",
    "from sports.configs.soccer import SoccerPitchConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model paths\n",
    "PARENT_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "PLAYER_DETECTION_MODEL_PATH = os.path.join(PARENT_DIR, 'data/football-player-detection.pt')\n",
    "PITCH_DETECTION_MODEL_PATH = os.path.join(PARENT_DIR, 'data/football-pitch-detection.pt')\n",
    "BALL_DETECTION_MODEL_PATH = os.path.join(PARENT_DIR, 'data/football-ball-detection.pt')\n",
    "\n",
    "# Class IDs\n",
    "BALL_CLASS_ID = 0\n",
    "GOALKEEPER_CLASS_ID = 1\n",
    "PLAYER_CLASS_ID = 2\n",
    "REFEREE_CLASS_ID = 3\n",
    "\n",
    "# Processing parameters\n",
    "STRIDE = 60\n",
    "CONFIG = SoccerPitchConfiguration()\n",
    "\n",
    "# Colors for visualization\n",
    "COLORS = ['#FF1493', '#00BFFF', '#FF6347', '#FFD700']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Annotators Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex and edge annotators for pitch\n",
    "VERTEX_LABEL_ANNOTATOR = sv.VertexLabelAnnotator(\n",
    "    color=[sv.Color.from_hex(color) for color in CONFIG.colors],\n",
    "    text_color=sv.Color.from_hex('#FFFFFF'),\n",
    "    border_radius=5,\n",
    "    text_thickness=1,\n",
    "    text_scale=0.5,\n",
    "    text_padding=5,\n",
    ")\n",
    "\n",
    "EDGE_ANNOTATOR = sv.EdgeAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    thickness=2,\n",
    "    edges=CONFIG.edges,\n",
    ")\n",
    "\n",
    "TRIANGLE_ANNOTATOR = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    base=20,\n",
    "    height=15,\n",
    ")\n",
    "\n",
    "# Box annotators for detections\n",
    "BOX_ANNOTATOR = sv.BoxAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(COLORS),\n",
    "    thickness=2\n",
    ")\n",
    "\n",
    "ELLIPSE_ANNOTATOR = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(COLORS),\n",
    "    thickness=2\n",
    ")\n",
    "\n",
    "# Label annotators\n",
    "BOX_LABEL_ANNOTATOR = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(COLORS),\n",
    "    text_color=sv.Color.from_hex('#FFFFFF'),\n",
    "    text_padding=5,\n",
    "    text_thickness=1,\n",
    ")\n",
    "\n",
    "ELLIPSE_LABEL_ANNOTATOR = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(COLORS),\n",
    "    text_color=sv.Color.from_hex('#FFFFFF'),\n",
    "    text_padding=5,\n",
    "    text_thickness=1,\n",
    "    text_position=sv.Position.BOTTOM_CENTER,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mode Enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mode(Enum):\n",
    "    \"\"\"\n",
    "    Enum class representing different modes of operation for Soccer AI video analysis.\n",
    "    \"\"\"\n",
    "    PITCH_DETECTION = 'PITCH_DETECTION'\n",
    "    PLAYER_DETECTION = 'PLAYER_DETECTION'\n",
    "    BALL_DETECTION = 'BALL_DETECTION'\n",
    "    PLAYER_TRACKING = 'PLAYER_TRACKING'\n",
    "    TEAM_CLASSIFICATION = 'TEAM_CLASSIFICATION'\n",
    "    RADAR = 'RADAR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crops(frame: np.ndarray, detections: sv.Detections) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract crops from the frame based on detected bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): The frame from which to extract crops.\n",
    "        detections (sv.Detections): Detected objects with bounding boxes.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: List of cropped images.\n",
    "    \"\"\"\n",
    "    return [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_goalkeepers_team_id(\n",
    "    players: sv.Detections,\n",
    "    players_team_id: np.array,\n",
    "    goalkeepers: sv.Detections\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resolve the team IDs for detected goalkeepers based on the proximity to team\n",
    "    centroids.\n",
    "\n",
    "    Args:\n",
    "        players (sv.Detections): Detections of all players.\n",
    "        players_team_id (np.array): Array containing team IDs of detected players.\n",
    "        goalkeepers (sv.Detections): Detections of goalkeepers.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array containing team IDs for the detected goalkeepers.\n",
    "\n",
    "    This function calculates the centroids of the two teams based on the positions of\n",
    "    the players. Then, it assigns each goalkeeper to the nearest team's centroid by\n",
    "    calculating the distance between each goalkeeper and the centroids of the two teams.\n",
    "    \"\"\"\n",
    "    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    team_0_centroid = players_xy[players_team_id == 0].mean(axis=0)\n",
    "    team_1_centroid = players_xy[players_team_id == 1].mean(axis=0)\n",
    "    goalkeepers_team_id = []\n",
    "    for goalkeeper_xy in goalkeepers_xy:\n",
    "        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n",
    "        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n",
    "        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)\n",
    "    return np.array(goalkeepers_team_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_radar(\n",
    "    detections: sv.Detections,\n",
    "    keypoints: sv.KeyPoints,\n",
    "    color_lookup: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a radar view by transforming player positions onto a 2D pitch representation.\n",
    "    Only uses keypoints that are actually detected (confidence > 0.5 and within frame).\n",
    "    \"\"\"\n",
    "    # Filter keypoints based on confidence and validity\n",
    "    all_keypoints = keypoints.xy[0]\n",
    "    all_confidence = keypoints.confidence[0] if keypoints.confidence is not None else np.ones(len(all_keypoints))\n",
    "    \n",
    "    # Create mask for valid keypoints (detected with confidence > 0.5 and not at origin)\n",
    "    mask = (all_keypoints[:, 0] > 1) & (all_keypoints[:, 1] > 1) & (all_confidence > 0.5)\n",
    "    \n",
    "    # Need at least 4 points for homography\n",
    "    if np.sum(mask) < 4:\n",
    "        return draw_pitch(config=CONFIG)\n",
    "    \n",
    "    # Filter source keypoints and corresponding target vertices\n",
    "    source_keypoints = all_keypoints[mask].astype(np.float32)\n",
    "    target_vertices = np.array(CONFIG.vertices)[mask].astype(np.float32)\n",
    "    \n",
    "    try:\n",
    "        transformer = ViewTransformer(\n",
    "            source=source_keypoints,\n",
    "            target=target_vertices\n",
    "        )\n",
    "        xy = detections.get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n",
    "        transformed_xy = transformer.transform_points(points=xy)\n",
    "\n",
    "        # Clip transformed coordinates to stay within pitch bounds\n",
    "        transformed_xy[:, 0] = np.clip(transformed_xy[:, 0], 0, CONFIG.length)\n",
    "        transformed_xy[:, 1] = np.clip(transformed_xy[:, 1], 0, CONFIG.width)\n",
    "\n",
    "    except (ValueError, cv2.error):\n",
    "        return draw_pitch(config=CONFIG)\n",
    "\n",
    "    radar = draw_pitch(config=CONFIG)\n",
    "    radar = draw_points_on_pitch(\n",
    "        config=CONFIG, xy=transformed_xy[color_lookup == 0],\n",
    "        face_color=sv.Color.from_hex(COLORS[0]), radius=20, pitch=radar)\n",
    "    radar = draw_points_on_pitch(\n",
    "        config=CONFIG, xy=transformed_xy[color_lookup == 1],\n",
    "        face_color=sv.Color.from_hex(COLORS[1]), radius=20, pitch=radar)\n",
    "    radar = draw_points_on_pitch(\n",
    "        config=CONFIG, xy=transformed_xy[color_lookup == 2],\n",
    "        face_color=sv.Color.from_hex(COLORS[2]), radius=20, pitch=radar)\n",
    "    radar = draw_points_on_pitch(\n",
    "        config=CONFIG, xy=transformed_xy[color_lookup == 3],\n",
    "        face_color=sv.Color.from_hex(COLORS[3]), radius=20, pitch=radar)\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detection and Tracking Functions\n",
    "\n",
    "### 6.1 Pitch Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pitch_detection(source_video_path: str, device: str) -> Iterator[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run pitch detection on a video and yield annotated frames.\n",
    "\n",
    "    Args:\n",
    "        source_video_path (str): Path to the source video.\n",
    "        device (str): Device to run the model on (e.g., 'cpu', 'cuda').\n",
    "\n",
    "    Yields:\n",
    "        Iterator[np.ndarray]: Iterator over annotated frames.\n",
    "    \"\"\"\n",
    "    pitch_detection_model = YOLO(PITCH_DETECTION_MODEL_PATH).to(device=device)\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=source_video_path)\n",
    "    for frame in frame_generator:\n",
    "        result = pitch_detection_model(frame, verbose=False)[0]\n",
    "        keypoints = sv.KeyPoints.from_ultralytics(result)\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = VERTEX_LABEL_ANNOTATOR.annotate(\n",
    "            annotated_frame, keypoints, CONFIG.labels)\n",
    "        yield annotated_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Player Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_player_detection(source_video_path: str, device: str) -> Iterator[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run player detection on a video and yield annotated frames.\n",
    "\n",
    "    Args:\n",
    "        source_video_path (str): Path to the source video.\n",
    "        device (str): Device to run the model on (e.g., 'cpu', 'cuda').\n",
    "\n",
    "    Yields:\n",
    "        Iterator[np.ndarray]: Iterator over annotated frames.\n",
    "    \"\"\"\n",
    "    player_detection_model = YOLO(PLAYER_DETECTION_MODEL_PATH).to(device=device)\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=source_video_path)\n",
    "    for frame in frame_generator:\n",
    "        result = player_detection_model(frame, imgsz=1280, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = BOX_ANNOTATOR.annotate(annotated_frame, detections)\n",
    "        annotated_frame = BOX_LABEL_ANNOTATOR.annotate(annotated_frame, detections)\n",
    "        yield annotated_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Ball Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ball_detection(source_video_path: str, device: str) -> Iterator[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run ball detection on a video and yield annotated frames.\n",
    "\n",
    "    Args:\n",
    "        source_video_path (str): Path to the source video.\n",
    "        device (str): Device to run the model on (e.g., 'cpu', 'cuda').\n",
    "\n",
    "    Yields:\n",
    "        Iterator[np.ndarray]: Iterator over annotated frames.\n",
    "    \"\"\"\n",
    "    ball_detection_model = YOLO(BALL_DETECTION_MODEL_PATH).to(device=device)\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=source_video_path)\n",
    "    ball_tracker = BallTracker(buffer_size=20)\n",
    "    ball_annotator = BallAnnotator(radius=6, buffer_size=10)\n",
    "\n",
    "    def callback(image_slice: np.ndarray) -> sv.Detections:\n",
    "        result = ball_detection_model(image_slice, imgsz=640, verbose=False)[0]\n",
    "        return sv.Detections.from_ultralytics(result)\n",
    "\n",
    "    slicer = sv.InferenceSlicer(\n",
    "        callback=callback,\n",
    "        overlap_filter_strategy=sv.OverlapFilter.NONE,\n",
    "        slice_wh=(640, 640),\n",
    "    )\n",
    "\n",
    "    for frame in frame_generator:\n",
    "        detections = slicer(frame).with_nms(threshold=0.1)\n",
    "        detections = ball_tracker.update(detections)\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = ball_annotator.annotate(annotated_frame, detections)\n",
    "        yield annotated_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Player Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_player_tracking(source_video_path: str, device: str) -> Iterator[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run player tracking on a video and yield annotated frames with tracked players.\n",
    "\n",
    "    Args:\n",
    "        source_video_path (str): Path to the source video.\n",
    "        device (str): Device to run the model on (e.g., 'cpu', 'cuda').\n",
    "\n",
    "    Yields:\n",
    "        Iterator[np.ndarray]: Iterator over annotated frames.\n",
    "    \"\"\"\n",
    "    player_detection_model = YOLO(PLAYER_DETECTION_MODEL_PATH).to(device=device)\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=source_video_path)\n",
    "    tracker = sv.ByteTrack(minimum_consecutive_frames=3)\n",
    "    for frame in frame_generator:\n",
    "        result = player_detection_model(frame, imgsz=1280, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "        detections = tracker.update_with_detections(detections)\n",
    "\n",
    "        labels = [str(tracker_id) for tracker_id in detections.tracker_id]\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = ELLIPSE_ANNOTATOR.annotate(annotated_frame, detections)\n",
    "        annotated_frame = ELLIPSE_LABEL_ANNOTATOR.annotate(\n",
    "            annotated_frame, detections, labels=labels)\n",
    "        yield annotated_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Team Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_team_classification(source_video_path: str, device: str) -> Iterator[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run team classification on a video and yield annotated frames with team colors.\n",
    "\n",
    "    Args:\n",
    "        source_video_path (str): Path to the source video.\n",
    "        device (str): Device to run the model on (e.g., 'cpu', 'cuda').\n",
    "\n",
    "    Yields:\n",
    "        Iterator[np.ndarray]: Iterator over annotated frames.\n",
    "    \"\"\"\n",
    "    player_detection_model = YOLO(PLAYER_DETECTION_MODEL_PATH).to(device=device)\n",
    "    frame_generator = sv.get_video_frames_generator(\n",
    "        source_path=source_video_path, stride=STRIDE)\n",
    "\n",
    "    crops = []\n",
    "    for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "        result = player_detection_model(frame, imgsz=1280, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "        crops += get_crops(frame, detections[detections.class_id == PLAYER_CLASS_ID])\n",
    "\n",
    "    team_classifier = TeamClassifier(device=device)\n",
    "    team_classifier.fit(crops)\n",
    "\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=source_video_path)\n",
    "    tracker = sv.ByteTrack(minimum_consecutive_frames=3)\n",
    "    for frame in frame_generator:\n",
    "        result = player_detection_model(frame, imgsz=1280, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "        detections = tracker.update_with_detections(detections)\n",
    "\n",
    "        players = detections[detections.class_id == PLAYER_CLASS_ID]\n",
    "        crops = get_crops(frame, players)\n",
    "        players_team_id = team_classifier.predict(crops)\n",
    "\n",
    "        goalkeepers = detections[detections.class_id == GOALKEEPER_CLASS_ID]\n",
    "        goalkeepers_team_id = resolve_goalkeepers_team_id(\n",
    "            players, players_team_id, goalkeepers)\n",
    "\n",
    "        referees = detections[detections.class_id == REFEREE_CLASS_ID]\n",
    "\n",
    "        detections = sv.Detections.merge([players, goalkeepers, referees])\n",
    "        color_lookup = np.array(\n",
    "                players_team_id.tolist() +\n",
    "                goalkeepers_team_id.tolist() +\n",
    "                [REFEREE_CLASS_ID] * len(referees)\n",
    "        )\n",
    "        labels = [str(tracker_id) for tracker_id in detections.tracker_id]\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = ELLIPSE_ANNOTATOR.annotate(\n",
    "            annotated_frame, detections, custom_color_lookup=color_lookup)\n",
    "        annotated_frame = ELLIPSE_LABEL_ANNOTATOR.annotate(\n",
    "            annotated_frame, detections, labels, custom_color_lookup=color_lookup)\n",
    "        yield annotated_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Radar View with Team Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_radar(source_video_path: str, device: str) -> Iterator[np.ndarray]:\n",
    "    player_detection_model = YOLO(PLAYER_DETECTION_MODEL_PATH).to(device=device)\n",
    "    pitch_detection_model = YOLO(PITCH_DETECTION_MODEL_PATH).to(device=device)\n",
    "    frame_generator = sv.get_video_frames_generator(\n",
    "        source_path=source_video_path, stride=STRIDE)\n",
    "\n",
    "    crops = []\n",
    "    for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "        result = player_detection_model(frame, imgsz=1280, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "        crops += get_crops(frame, detections[detections.class_id == PLAYER_CLASS_ID])\n",
    "\n",
    "    team_classifier = TeamClassifier(device=device)\n",
    "    team_classifier.fit(crops)\n",
    "\n",
    "    frame_generator = sv.get_video_frames_generator(source_path=source_video_path)\n",
    "    tracker = sv.ByteTrack(minimum_consecutive_frames=3)\n",
    "    for frame in frame_generator:\n",
    "        result = pitch_detection_model(frame, verbose=False)[0]\n",
    "        keypoints = sv.KeyPoints.from_ultralytics(result)\n",
    "        result = player_detection_model(frame, imgsz=1280, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "        detections = tracker.update_with_detections(detections)\n",
    "\n",
    "        players = detections[detections.class_id == PLAYER_CLASS_ID]\n",
    "        crops = get_crops(frame, players)\n",
    "        players_team_id = team_classifier.predict(crops)\n",
    "\n",
    "        goalkeepers = detections[detections.class_id == GOALKEEPER_CLASS_ID]\n",
    "        goalkeepers_team_id = resolve_goalkeepers_team_id(\n",
    "            players, players_team_id, goalkeepers)\n",
    "\n",
    "        referees = detections[detections.class_id == REFEREE_CLASS_ID]\n",
    "\n",
    "        detections = sv.Detections.merge([players, goalkeepers, referees])\n",
    "        color_lookup = np.array(\n",
    "            players_team_id.tolist() +\n",
    "            goalkeepers_team_id.tolist() +\n",
    "            [REFEREE_CLASS_ID] * len(referees)\n",
    "        )\n",
    "        labels = [str(tracker_id) for tracker_id in detections.tracker_id]\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = ELLIPSE_ANNOTATOR.annotate(\n",
    "            annotated_frame, detections, custom_color_lookup=color_lookup)\n",
    "        annotated_frame = ELLIPSE_LABEL_ANNOTATOR.annotate(\n",
    "            annotated_frame, detections, labels,\n",
    "            custom_color_lookup=color_lookup)\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "        radar = render_radar(detections, keypoints, color_lookup)\n",
    "        radar = sv.resize_image(radar, (w // 2, h // 2))\n",
    "        radar_h, radar_w, _ = radar.shape\n",
    "        rect = sv.Rect(\n",
    "            x=w // 2 - radar_w // 2,\n",
    "            y=h - radar_h,\n",
    "            width=radar_w,\n",
    "            height=radar_h\n",
    "        )\n",
    "        annotated_frame = sv.draw_image(annotated_frame, radar, opacity=0.5, rect=rect)\n",
    "        yield annotated_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(source_video_path: str, target_video_path: str, device: str, mode: Mode) -> None:\n",
    "    if mode == Mode.PITCH_DETECTION:\n",
    "        frame_generator = run_pitch_detection(\n",
    "            source_video_path=source_video_path, device=device)\n",
    "    elif mode == Mode.PLAYER_DETECTION:\n",
    "        frame_generator = run_player_detection(\n",
    "            source_video_path=source_video_path, device=device)\n",
    "    elif mode == Mode.BALL_DETECTION:\n",
    "        frame_generator = run_ball_detection(\n",
    "            source_video_path=source_video_path, device=device)\n",
    "    elif mode == Mode.PLAYER_TRACKING:\n",
    "        frame_generator = run_player_tracking(\n",
    "            source_video_path=source_video_path, device=device)\n",
    "    elif mode == Mode.TEAM_CLASSIFICATION:\n",
    "        frame_generator = run_team_classification(\n",
    "            source_video_path=source_video_path, device=device)\n",
    "    elif mode == Mode.RADAR:\n",
    "        frame_generator = run_radar(\n",
    "            source_video_path=source_video_path, device=device)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Mode {mode} is not implemented.\")\n",
    "\n",
    "    video_info = sv.VideoInfo.from_video_path(source_video_path)\n",
    "    \n",
    "    # Get screen resolution and calculate appropriate scale\n",
    "    root = tk.Tk()\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "    root.destroy()\n",
    "    \n",
    "    # Use 90% of screen height to leave room for taskbar\n",
    "    max_display_height = int(screen_height * 0.9)\n",
    "    max_display_width = int(screen_width * 0.9)\n",
    "    \n",
    "    with sv.VideoSink(target_video_path, video_info) as sink:\n",
    "        for frame in frame_generator:\n",
    "            sink.write_frame(frame)\n",
    "\n",
    "            # Resize frame to fit screen\n",
    "            h, w = frame.shape[:2]\n",
    "            scale = min(max_display_width / w, max_display_height / h)\n",
    "            if scale < 1:\n",
    "                display_frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "            else:\n",
    "                display_frame = frame\n",
    "            \n",
    "            cv2.imshow(\"frame\", display_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Analysis\n",
    "\n",
    "Configure your analysis parameters below and run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.config', 'drive', 'sample_data']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())  # Shows files in the current working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 10sec.mp4\n",
      "Mode: PLAYER_DETECTION\n",
      "Device: cpu\n",
      "Output will be saved to: output_video.mp4\n",
      "\n",
      "Press 'q' to stop processing early.\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Could not open video at 10sec.mp4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1630235185.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPress 'q' to stop processing early.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m main(\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0msource_video_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_video_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtarget_video_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_video_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1385392454.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(source_video_path, target_video_path, device, mode)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mode {mode} is not implemented.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mvideo_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_video_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_video_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Get screen resolution and calculate appropriate scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/supervision/utils/video.py\u001b[0m in \u001b[0;36mfrom_video_path\u001b[0;34m(cls, video_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not open video at {video_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_FRAME_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Could not open video at 10sec.mp4"
     ]
    }
   ],
   "source": [
    "# # Configuration\n",
    "# source_video_path = '10sec.mp4'  # Update this path\n",
    "# target_video_path = 'path/to/output/video.mp4'  # Update this path\n",
    "# device = 'cpu'  # Use 'cuda' for GPU acceleration\n",
    "# mode = Mode.PLAYER_DETECTION  # Choose from: PITCH_DETECTION, PLAYER_DETECTION, BALL_DETECTION, \n",
    "#                                # PLAYER_TRACKING, TEAM_CLASSIFICATION, RADAR\n",
    "\n",
    "# # Run the analysis\n",
    "# main(\n",
    "#     source_video_path=source_video_path,\n",
    "#     target_video_path=target_video_path,\n",
    "#     device=device,\n",
    "#     mode=mode\n",
    "# )\n",
    "\n",
    "# Configuration\n",
    "# Update these paths to your actual video files\n",
    "source_video_path = '10sec.mp4'  # Path to your input video\n",
    "target_video_path = 'output_video.mp4'  # Path where output will be saved\n",
    "\n",
    "# Device configuration\n",
    "device = 'cpu'  # Use 'cuda' for GPU acceleration if available\n",
    "\n",
    "# Mode selection - uncomment the one you want to use:\n",
    "mode = Mode.PLAYER_DETECTION\n",
    "# mode = Mode.PITCH_DETECTION\n",
    "# mode = Mode.BALL_DETECTION\n",
    "# mode = Mode.PLAYER_TRACKING\n",
    "# mode = Mode.TEAM_CLASSIFICATION\n",
    "# mode = Mode.RADAR\n",
    "\n",
    "# Run the analysis\n",
    "print(f\"Processing video: {source_video_path}\")\n",
    "print(f\"Mode: {mode.value}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Output will be saved to: {target_video_path}\")\n",
    "print(\"\\nPress 'q' to stop processing early.\\n\")\n",
    "\n",
    "main(\n",
    "    source_video_path=source_video_path,\n",
    "    target_video_path=target_video_path,\n",
    "    device=device,\n",
    "    mode=mode\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Processing complete! Video saved to: {target_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
